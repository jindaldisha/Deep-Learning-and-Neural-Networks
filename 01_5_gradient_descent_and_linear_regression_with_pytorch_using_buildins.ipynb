{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "00_4_gradient_descent_and_linear_regression_with_pytorch_using_buildins.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObOWQC003UUkiDjhdKWVRC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jindaldisha/Deep-Learning-and-Neural-Networks/blob/main/00_4_gradient_descent_and_linear_regression_with_pytorch_using_buildins.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6v6acRdCmac"
      },
      "source": [
        "#Linear regression using PyTorch built-ins\n",
        "\n",
        "PyTorch provides several built-in functions and classes to make it easy to create and train models with just a few lines of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biJmEPMoBuJ7"
      },
      "source": [
        "#Import Libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn #contains utility classes for building neural networks."
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZLindyBC4aa"
      },
      "source": [
        "##Training data\n",
        "\n",
        "We'll represent the training data using matrics x_train and y_train.\n",
        "\n",
        "x_train will have the values of temperature, rainfall and humidity for every region as a single row each.\n",
        "y_train will have the crop yields of apples and oranges for every region as a single row each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G08QPu2gDXfz"
      },
      "source": [
        "# Input Features (temp, rainfall, humidity)\n",
        "x_train = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70], \n",
        "                   [74, 66, 43], \n",
        "                   [91, 87, 65], \n",
        "                   [88, 134, 59], \n",
        "                   [101, 44, 37], \n",
        "                   [68, 96, 71], \n",
        "                   [73, 66, 44], \n",
        "                   [92, 87, 64], \n",
        "                   [87, 135, 57], \n",
        "                   [103, 43, 36], \n",
        "                   [68, 97, 70]], \n",
        "                  dtype='float32')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX-FbOfgDjXO"
      },
      "source": [
        "# Input Labels (apples, oranges)\n",
        "y_train = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119],\n",
        "                    [57, 69], \n",
        "                    [80, 102], \n",
        "                    [118, 132], \n",
        "                    [21, 38], \n",
        "                    [104, 118], \n",
        "                    [57, 69], \n",
        "                    [82, 100], \n",
        "                    [118, 134], \n",
        "                    [20, 38], \n",
        "                    [102, 120]], \n",
        "                   dtype='float32')"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNjIAqvoDjUh"
      },
      "source": [
        "#Convert input numpy arrays to pytorch tensors\n",
        "x_train = torch.from_numpy(x_train)\n",
        "y_train = torch.from_numpy(y_train)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUX2rr5MDtCX"
      },
      "source": [
        "##Dataset and DataLoader\n",
        "\n",
        "We'll create a `TensorDataset`, which allows access to rows from `x_train` and `y_train` as tuples, and provides standard APIs for working with many different types of datasets in PyTorch.\n",
        "\n",
        "\n",
        "When working with large datasets, its not possible to train the entire dataset at once as it may not fit into the memory and even if it does, the entire process will be very slow.\n",
        "And therefore what we do instead is take the dataset and break it into batches and train our model batch by batch.\n",
        "\n",
        "The `TensorDataset` allows us to access a small section of the training data using the array indexing notation. It returns a tuple with two elements. The first element contains the input variables for the selected rows, and the second contains the targets.\n",
        "\n",
        "We'll also create a `DataLoader`, which can split the data into batches of a predefined size while training. It also provides other utilities like shuffling and random sampling of the data.\n",
        "\n",
        "We can set the `shuffle = True` in `DataLoader`. This helps randomize the input to optimization algorithm, leading to a faster reduction in loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdMmEM1oOP3Y"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56vB-qg0P_4V",
        "outputId": "15fc42bc-73aa-4e40-8026-b9a1231e4257"
      },
      "source": [
        "#Define data\n",
        "train_ds = TensorDataset(x_train, y_train)\n",
        "#Viewing a single example\n",
        "train_ds[0]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([73., 67., 43.]), tensor([56., 70.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFPDaUDaQYs_"
      },
      "source": [
        "#Define data loader\n",
        "batch_size = 5\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj7m354WRLAD",
        "outputId": "ec5b4fc3-aadf-4880-a5e8-33b70db46660"
      },
      "source": [
        "#Viewing the batches - each iteration displays a batch\n",
        "for xb, yb in train_dl:\n",
        "    print(xb)\n",
        "    print(yb)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 68.,  96.,  71.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [ 91.,  87.,  65.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 73.,  66.,  44.]])\n",
            "tensor([[104., 118.],\n",
            "        [119., 133.],\n",
            "        [ 80., 102.],\n",
            "        [ 81., 101.],\n",
            "        [ 57.,  69.]])\n",
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 69.,  96.,  70.],\n",
            "        [ 88., 134.,  59.],\n",
            "        [ 87., 135.,  57.],\n",
            "        [ 92.,  87.,  64.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [103., 119.],\n",
            "        [118., 132.],\n",
            "        [118., 134.],\n",
            "        [ 82., 100.]])\n",
            "tensor([[ 68.,  97.,  70.],\n",
            "        [102.,  43.,  37.],\n",
            "        [101.,  44.,  37.],\n",
            "        [ 74.,  66.,  43.],\n",
            "        [103.,  43.,  36.]])\n",
            "tensor([[102., 120.],\n",
            "        [ 22.,  37.],\n",
            "        [ 21.,  38.],\n",
            "        [ 57.,  69.],\n",
            "        [ 20.,  38.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUsjgqYFRQEO"
      },
      "source": [
        "##nn.Linear\n",
        "\n",
        "Instead of initializing the weights and biases manually, we can defin the model using `nn.Linear` class from PyTorch, which does it automatically. It is a linear layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R4i8E5USgm8",
        "outputId": "afa41f45-f0d5-4064-d329-57249e7f8923"
      },
      "source": [
        "#Define model\n",
        "model = nn.Linear(3,2) #(no. of inputs, no. of outputs)\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0533, -0.5322, -0.4030],\n",
            "        [-0.3642,  0.2834, -0.5382]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.2873, 0.1964], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYwKM2bUSpUG"
      },
      "source": [
        "PyTorch also has a `.parameter` method, which returns a list containing all the weights and biases matrics present in the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2N4CTPWSmV3",
        "outputId": "fde6e3f5-f6ed-4e4a-f970-6d06febc9ab1"
      },
      "source": [
        "#Parameters\n",
        "list(model.parameters())"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.0533, -0.5322, -0.4030],\n",
              "         [-0.3642,  0.2834, -0.5382]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.2873, 0.1964], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBFBA7pOS56u",
        "outputId": "b7e80536-33ee-4c0e-ea8b-460a7eec54d1"
      },
      "source": [
        "#Generate predictions\n",
        "y_pred = model(x_train)\n",
        "y_pred"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-48.8023, -30.5447],\n",
              "        [-67.4799, -42.4512],\n",
              "        [-89.7546, -24.7297],\n",
              "        [-32.0668, -44.6778],\n",
              "        [-75.3278, -35.4014],\n",
              "        [-48.2168, -31.1923],\n",
              "        [-67.3507, -43.2728],\n",
              "        [-90.1042, -25.6321],\n",
              "        [-32.6522, -44.0303],\n",
              "        [-75.7840, -35.5754],\n",
              "        [-48.6731, -31.3663],\n",
              "        [-66.8945, -43.0987],\n",
              "        [-89.8838, -23.9082],\n",
              "        [-31.6105, -44.5038],\n",
              "        [-75.9132, -34.7539]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdPX_Qx0Ue2U"
      },
      "source": [
        "##Loss Function\n",
        "\n",
        "We can use the build-in loss function `mse_loss`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWs9FkpDXu1U"
      },
      "source": [
        "# Import nn.functional\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qfKwWFtXxq-"
      },
      "source": [
        "# Define loss function\n",
        "loss_fn = F.mse_loss"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD8btc5GU0le",
        "outputId": "f1f391e2-d5c2-4dda-9e8a-708c4d2c61f9"
      },
      "source": [
        "#Calculate loss for the model\n",
        "loss = loss_fn(y_pred, y_train)\n",
        "print(loss)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(19737.1836, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhetGeAoVFDb"
      },
      "source": [
        "## Optimizer\n",
        "\n",
        "Instead of manually manipulating the model's weights & biases using gradients, we can use the optimizer `optim.SGD`. SGD is short for \"stochastic gradient descent\". The term _stochastic_ indicates that samples are selected in random batches instead of as a single group.\n",
        "\n",
        "`model.parameters()` is passed as an argument to `optim.SGD` so that the optimizer knows which matrices should be modified during the update step. Also, we can specify a learning rate that controls the amount by which the parameters are modified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94IrKRrgVW4D"
      },
      "source": [
        "#Define Optimizer\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcL4PIYKWMlC"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "We'll follow the following process to implement gradient descent:\n",
        "\n",
        "1. Generate predictions\n",
        "2. Calculate the loss\n",
        "3. Compute gradients w.r.t the weights and biases\n",
        "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
        "5. Reset the gradients to zero\n",
        "\n",
        "\n",
        "Note:\n",
        " - We'll work batches of data instead of processing the entire training data in every iteration. We use the data loader defined earlier to get batches of data for every iteration.\n",
        "\n",
        " - Instead of updating parameters (weights and biases) manually, we use `opt.step` to perform the update and `opt.zero_grad` to reset the gradients to zero.\n",
        "\n",
        " - We've also added a log statement that prints the loss from the last batch of data for every epoch to track training progress. `loss.item` returns the actual value stored in the loss tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaTjKVuuVoOS"
      },
      "source": [
        "#Utility function to train (fit) the model \n",
        "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
        "  #Repeat for given number of epochs\n",
        "  for epoch in range(num_epochs):\n",
        "    #Train with batches of data\n",
        "    for xb, yb in train_dl:\n",
        "\n",
        "      # 1. Generate predictions\n",
        "      y_pred = model(xb)\n",
        "\n",
        "      # 2. Calculate Loss\n",
        "      loss = torch.nn.functional.mse_loss(y_pred, yb)\n",
        "\n",
        "      # 3. Compute gradients\n",
        "      loss.backward()\n",
        "\n",
        "      # 4. Update parameters using gradients\n",
        "      opt.step()\n",
        "\n",
        "      # 5. Reset the gradients to zero\n",
        "      opt.zero_grad()\n",
        "    \n",
        "    #Print progress\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2w2ltULYTvf",
        "outputId": "766a011e-e5f4-4c44-b7cb-09d942dadce7"
      },
      "source": [
        "#Fit the Model for 100 epochs\n",
        "fit(100, model, loss_fn, opt, train_dl)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Loss: 10200.880859375\n",
            "Epoch [2/100], Loss: 6400.791015625\n",
            "Epoch [3/100], Loss: 1234.308349609375\n",
            "Epoch [4/100], Loss: 619.7398071289062\n",
            "Epoch [5/100], Loss: 540.5086669921875\n",
            "Epoch [6/100], Loss: 904.9818115234375\n",
            "Epoch [7/100], Loss: 1014.5422973632812\n",
            "Epoch [8/100], Loss: 226.34780883789062\n",
            "Epoch [9/100], Loss: 637.846435546875\n",
            "Epoch [10/100], Loss: 755.33935546875\n",
            "Epoch [11/100], Loss: 337.67962646484375\n",
            "Epoch [12/100], Loss: 585.8490600585938\n",
            "Epoch [13/100], Loss: 680.42578125\n",
            "Epoch [14/100], Loss: 430.82080078125\n",
            "Epoch [15/100], Loss: 418.80462646484375\n",
            "Epoch [16/100], Loss: 647.3411865234375\n",
            "Epoch [17/100], Loss: 37.851680755615234\n",
            "Epoch [18/100], Loss: 367.4296875\n",
            "Epoch [19/100], Loss: 578.204345703125\n",
            "Epoch [20/100], Loss: 156.33804321289062\n",
            "Epoch [21/100], Loss: 198.8542938232422\n",
            "Epoch [22/100], Loss: 554.1481323242188\n",
            "Epoch [23/100], Loss: 138.4562530517578\n",
            "Epoch [24/100], Loss: 465.9931640625\n",
            "Epoch [25/100], Loss: 490.10040283203125\n",
            "Epoch [26/100], Loss: 274.4853210449219\n",
            "Epoch [27/100], Loss: 261.1819763183594\n",
            "Epoch [28/100], Loss: 265.4781188964844\n",
            "Epoch [29/100], Loss: 135.47305297851562\n",
            "Epoch [30/100], Loss: 189.00872802734375\n",
            "Epoch [31/100], Loss: 245.6149139404297\n",
            "Epoch [32/100], Loss: 330.3023376464844\n",
            "Epoch [33/100], Loss: 38.87151336669922\n",
            "Epoch [34/100], Loss: 326.88897705078125\n",
            "Epoch [35/100], Loss: 222.43173217773438\n",
            "Epoch [36/100], Loss: 172.38343811035156\n",
            "Epoch [37/100], Loss: 201.4496307373047\n",
            "Epoch [38/100], Loss: 212.69125366210938\n",
            "Epoch [39/100], Loss: 220.49722290039062\n",
            "Epoch [40/100], Loss: 341.7757263183594\n",
            "Epoch [41/100], Loss: 255.56771850585938\n",
            "Epoch [42/100], Loss: 222.83773803710938\n",
            "Epoch [43/100], Loss: 272.73828125\n",
            "Epoch [44/100], Loss: 232.2853240966797\n",
            "Epoch [45/100], Loss: 153.5781707763672\n",
            "Epoch [46/100], Loss: 161.08737182617188\n",
            "Epoch [47/100], Loss: 97.51837921142578\n",
            "Epoch [48/100], Loss: 43.32466125488281\n",
            "Epoch [49/100], Loss: 308.8177795410156\n",
            "Epoch [50/100], Loss: 202.66827392578125\n",
            "Epoch [51/100], Loss: 211.35690307617188\n",
            "Epoch [52/100], Loss: 283.8255615234375\n",
            "Epoch [53/100], Loss: 138.60821533203125\n",
            "Epoch [54/100], Loss: 130.32620239257812\n",
            "Epoch [55/100], Loss: 129.21656799316406\n",
            "Epoch [56/100], Loss: 140.28494262695312\n",
            "Epoch [57/100], Loss: 83.82625579833984\n",
            "Epoch [58/100], Loss: 50.61970138549805\n",
            "Epoch [59/100], Loss: 85.78370666503906\n",
            "Epoch [60/100], Loss: 116.4732894897461\n",
            "Epoch [61/100], Loss: 111.34431457519531\n",
            "Epoch [62/100], Loss: 74.80708312988281\n",
            "Epoch [63/100], Loss: 110.04520416259766\n",
            "Epoch [64/100], Loss: 106.50760650634766\n",
            "Epoch [65/100], Loss: 73.70479583740234\n",
            "Epoch [66/100], Loss: 69.2046890258789\n",
            "Epoch [67/100], Loss: 33.331417083740234\n",
            "Epoch [68/100], Loss: 96.2431869506836\n",
            "Epoch [69/100], Loss: 68.67666625976562\n",
            "Epoch [70/100], Loss: 92.01849365234375\n",
            "Epoch [71/100], Loss: 105.26402282714844\n",
            "Epoch [72/100], Loss: 70.45541381835938\n",
            "Epoch [73/100], Loss: 112.00838470458984\n",
            "Epoch [74/100], Loss: 68.49933624267578\n",
            "Epoch [75/100], Loss: 117.27459716796875\n",
            "Epoch [76/100], Loss: 90.11381530761719\n",
            "Epoch [77/100], Loss: 120.8958511352539\n",
            "Epoch [78/100], Loss: 77.52757263183594\n",
            "Epoch [79/100], Loss: 34.19255828857422\n",
            "Epoch [80/100], Loss: 101.98934936523438\n",
            "Epoch [81/100], Loss: 68.6674575805664\n",
            "Epoch [82/100], Loss: 97.22648620605469\n",
            "Epoch [83/100], Loss: 56.801780700683594\n",
            "Epoch [84/100], Loss: 50.429229736328125\n",
            "Epoch [85/100], Loss: 91.20223236083984\n",
            "Epoch [86/100], Loss: 66.33724212646484\n",
            "Epoch [87/100], Loss: 30.356298446655273\n",
            "Epoch [88/100], Loss: 45.17135238647461\n",
            "Epoch [89/100], Loss: 30.441299438476562\n",
            "Epoch [90/100], Loss: 81.88887023925781\n",
            "Epoch [91/100], Loss: 49.44445037841797\n",
            "Epoch [92/100], Loss: 80.42893981933594\n",
            "Epoch [93/100], Loss: 75.87389373779297\n",
            "Epoch [94/100], Loss: 65.67838287353516\n",
            "Epoch [95/100], Loss: 68.54997253417969\n",
            "Epoch [96/100], Loss: 32.038963317871094\n",
            "Epoch [97/100], Loss: 74.81272888183594\n",
            "Epoch [98/100], Loss: 84.28462982177734\n",
            "Epoch [99/100], Loss: 75.4465560913086\n",
            "Epoch [100/100], Loss: 47.30143356323242\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meonVlKuYaCd",
        "outputId": "3209257e-f5b2-4635-e747-50c84b1b628b"
      },
      "source": [
        "#Generate predictions\n",
        "y_pred = model(x_train)\n",
        "y_pred"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 58.8174,  71.4142],\n",
              "        [ 80.0736,  95.1983],\n",
              "        [119.5106, 142.8298],\n",
              "        [ 31.1705,  43.2479],\n",
              "        [ 92.4786, 106.0793],\n",
              "        [ 57.7700,  70.2926],\n",
              "        [ 79.4725,  94.2972],\n",
              "        [119.6198, 142.9036],\n",
              "        [ 32.2179,  44.3694],\n",
              "        [ 92.9249, 106.2996],\n",
              "        [ 58.2163,  70.5130],\n",
              "        [ 79.0262,  94.0768],\n",
              "        [120.1117, 143.7310],\n",
              "        [ 30.7242,  43.0275],\n",
              "        [ 93.5260, 107.2008]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcuU7AczZwdy",
        "outputId": "eb5a03f0-b543-499a-9041-5a08a198b11c"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 57.,  69.],\n",
              "        [ 80., 102.],\n",
              "        [118., 132.],\n",
              "        [ 21.,  38.],\n",
              "        [104., 118.],\n",
              "        [ 57.,  69.],\n",
              "        [ 82., 100.],\n",
              "        [118., 134.],\n",
              "        [ 20.,  38.],\n",
              "        [102., 120.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIOIMGuVZ4Td"
      },
      "source": [
        "The predictions are quite close to our targets. We have a trained a reasonably good model to predict crop yields for apples and oranges by looking at the average temperature, rainfall, and humidity in a region. We can use it to make predictions of crop yields for new regions by passing a batch containing a single row of input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLsHy1HhaCrt"
      },
      "source": [
        "The approach in machine learning is very different from classical programming. Usually we write programs that take some inputs, perform some operations and return the result. \n",
        "However, here we've defined a 'mode' that assumes a specific relation between the inputs and outputs, expresses using some random parameters i.e. weights and biases. We then show the model some known inputs and outputs and train the model to come up with good values for the unknown parameters. Once trained the model can be used to compute the outputs for new inputs.Deep learning is a branch of machine learning that uses matrix operations, non-linear activation functions and gradient descent to build and train models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cocN79isZxqi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
